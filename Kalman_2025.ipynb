{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2025 CVE Time Series Forecasting using Kalman Filter\n",
    "\n",
    "This notebook demonstrates a full workflow for forecasting Common Vulnerabilities and Exposures (CVE) counts for 2025 using the Kalman Filter. The process includes:\n",
    "- Loading and validating CVE data from the National Vulnerability Database (NVD) JSONL export\n",
    "- Aggregating and exploring the dataset\n",
    "- Running diagnostics and visualizations\n",
    "- Fitting a Kalman Filter model and generating forecasts\n",
    "- Comparing predictions to actuals for 2025\n",
    "\n",
    "**Goal:** Provide a reproducible, transparent, and robust time series forecasting pipeline for CVE data, with clear diagnostics and validation steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source and License\n",
    "- **Data Source:** [NVD Data Feeds](https://nvd.nist.gov/vuln/data-feeds) (JSONL export)\n",
    "- **License:** Data is provided by NIST and is in the public domain. See: https://www.nist.gov/open/license\n",
    "- **Background on the Kalman Filter:** [Wikipedia](https://en.wikipedia.org/wiki/Kalman_filter)\n",
    "- **Python Library Used:** [Darts Time Series Library](https://unit8co.github.io/darts/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Introduction](#2025-cve-time-series-forecasting-using-kalman-filter)\n",
    "- [Data Source and License](#data-source-and-license)\n",
    "- [Configuration](#configuration)\n",
    "- [1. Import Required Libraries](#1-import-required-libraries)\n",
    "- [2. Load and Prepare CVE Data](#2-load-and-prepare-cve-data)\n",
    "- [3. Dataset Overview](#3-dataset-overview)\n",
    "- [4. Monthly Aggregation](#4-monthly-aggregation)\n",
    "- [5. Diagnostics](#5-diagnostics)\n",
    "- [6. Kalman Filter Forecasting](#6-kalman-filter-forecasting)\n",
    "- [7. Post-Processing Forecast Results](#7-post-processing-forecast-results)\n",
    "- [8. Validation Against Actuals](#8-validation-against-actuals)\n",
    "- [9. Conclusion](#9-conclusion)\n",
    "- [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Set key parameters and file paths here for easy adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration cell for key parameters\n",
    "from datetime import date  # Ensure date is imported before use\n",
    "DATA_FILE = 'nvd.jsonl'\n",
    "START_DATE = '2017-01-01'\n",
    "FORECAST_YEAR = 2025\n",
    "\n",
    "# Derived parameters\n",
    "END_DATE = date.today().strftime('%Y-%m-%d')\n",
    "NEXT_YEAR = str(FORECAST_YEAR + 1) + '-01-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "All necessary libraries for data loading, processing, and forecasting are imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T12:09:58.480497Z",
     "iopub.status.busy": "2025-06-29T12:09:58.480064Z",
     "iopub.status.idle": "2025-06-29T12:10:03.597214Z",
     "shell.execute_reply": "2025-06-29T12:10:03.596576Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from IPython.display import Markdown\n",
    "from datetime import date\n",
    "import glob\n",
    "import json\n",
    "import matplotlib\n",
    "# Set matplotlib backend for headless environments (CI/CD)\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import KalmanForecaster\n",
    "\n",
    "np.seterr(all=\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare CVE Data\n",
    "This section loads the CVE data from the JSONL file and prepares it for analysis. If the file is missing or invalid, a user-friendly error will be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 299832 CVE records\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Check if data file exists with retry logic (useful for CI environments)\n",
    "max_retries = 3\n",
    "retry_count = 0\n",
    "while retry_count < max_retries:\n",
    "    if os.path.exists(DATA_FILE):\n",
    "        break\n",
    "    print(f\"Data file '{DATA_FILE}' not found. Retry {retry_count + 1}/{max_retries}\")\n",
    "    time.sleep(2)  # Wait 2 seconds before retry\n",
    "    retry_count += 1\n",
    "\n",
    "if not os.path.exists(DATA_FILE):\n",
    "    raise FileNotFoundError(f\"Data file '{DATA_FILE}' not found after {max_retries} retries. Please ensure the file is present in the workspace.\")\n",
    "\n",
    "# Additional data validation with better error messages\n",
    "try:\n",
    "    with open(DATA_FILE, 'r', encoding='utf-8') as f:\n",
    "        nvd_data = json.load(f)\n",
    "    if not isinstance(nvd_data, list):\n",
    "        raise ValueError(f\"Expected data to be a list, got {type(nvd_data)}\")\n",
    "    if len(nvd_data) == 0:\n",
    "        raise ValueError(\"Loaded data is empty\")\n",
    "    print(f\"Successfully loaded {len(nvd_data)} CVE records\")\n",
    "except json.JSONDecodeError as e:\n",
    "    raise RuntimeError(f\"Invalid JSON format in data file: {e}\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error loading or validating data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T12:10:03.612384Z",
     "iopub.status.busy": "2025-06-29T12:10:03.611712Z",
     "iopub.status.idle": "2025-06-29T12:10:29.346381Z",
     "shell.execute_reply": "2025-06-29T12:10:29.345777Z"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 21 (1769176081.py, line 24)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mnew_row = {\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m expected an indented block after 'if' statement on line 21\n"
     ]
    }
   ],
   "source": [
    "def get_nested_value(entry, keys, default='Missing_Data'):\n",
    "    try:\n",
    "        for key in keys:\n",
    "            entry = entry[key]\n",
    "        return entry\n",
    "    except (KeyError, IndexError, TypeError):\n",
    "        return default\n",
    "\n",
    "# Process data in batches to reduce memory usage\n",
    "row_accumulator = []\n",
    "batch_size = 1000  # Process in smaller batches for better memory management\n",
    "\n",
    "for filename in glob.glob(DATA_FILE):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        nvd_data = json.load(f)\n",
    "        total_entries = len(nvd_data)\n",
    "        # print(f\"Processing {total_entries} CVE entries...\")\n",
    "        \n",
    "        for i, entry in enumerate(nvd_data):\n",
    "            # Progress reporting for CI logs\n",
    "            if i % 5000 == 0 and i > 0:\n",
    "            # print(f\"Processed {i}/{total_entries} entries ({i/total_entries*100:.1f}%)\")\n",
    "            \n",
    "            new_row = {\n",
    "                'CVE': get_nested_value(entry, ['cve', 'id']),\n",
    "                'Published': get_nested_value(entry, ['cve', 'published']),\n",
    "                'AttackVector': get_nested_value(entry, ['cve', 'metrics', 'cvssMetricV31', 0, 'cvssData', 'attackVector']),\n",
    "                'AttackComplexity': get_nested_value(entry, ['cve', 'metrics', 'cvssMetricV31', 0, 'cvssData', 'attackComplexity']),\n",
    "                'PrivilegesRequired': get_nested_value(entry, ['cve', 'metrics', 'cvssMetricV31', 0, 'cvssData', 'privilegesRequired']),\n",
    "                'UserInteraction': get_nested_value(entry, ['cve', 'metrics', 'cvssMetricV31', 0, 'cvssData', 'userInteraction']),\n",
    "                'Scope': get_nested_value(entry, ['cve', 'metrics', 'cvssMetricV31', 0, 'cvssData', 'scope']),\n",
    "                'ConfidentialityImpact': get_nested_value(entry, ['cve', 'metrics', 'cvssMetricV31', 0, 'cvssData', 'confidentialityImpact']),\n",
    "                'IntegrityImpact': get_nested_value(entry, ['cve', 'metrics', 'cvssMetricV31', 0, 'cvssData', 'integrityImpact']),\n",
    "                'AvailabilityImpact': get_nested_value(entry, ['cve', 'metrics', 'cvssMetricV31', 0, 'cvssData', 'availabilityImpact']),\n",
    "                'BaseScore': get_nested_value(entry, ['cve', 'metrics', 'cvssMetricV31', 0, 'cvssData', 'baseScore'], '0.0'),\n",
    "                'BaseSeverity': get_nested_value(entry, ['cve', 'metrics', 'cvssMetricV31', 0, 'cvssData', 'baseSeverity']),\n",
    "                'ExploitabilityScore': get_nested_value(entry, ['cve', 'metrics', 'cvssMetricV31', 0, 'exploitabilityScore']),\n",
    "                'ImpactScore': get_nested_value(entry, ['cve', 'metrics', 'cvssMetricV31', 0, 'impactScore']),\n",
    "                'CWE': get_nested_value(entry, ['cve', 'weaknesses', 0, 'description', 0, 'value']),\n",
    "                'Description': get_nested_value(entry, ['cve', 'descriptions', 0, 'value'], ''),\n",
    "                'Assigner': get_nested_value(entry, ['cve', 'sourceIdentifier']),\n",
    "                'Tag': get_nested_value(entry, ['cve', 'cveTags', 0, 'tags'], np.nan),\n",
    "                'Status': get_nested_value(entry, ['cve', 'vulnStatus'], '')\n",
    "            }\n",
    "            row_accumulator.append(new_row)\n",
    "\n",
    "#print(\"Creating DataFrame...\")\n",
    "nvd = pd.DataFrame(row_accumulator)\n",
    "#print(f\"Created DataFrame with {len(nvd)} rows\")\n",
    "\n",
    "# Clear row_accumulator to free memory\n",
    "del row_accumulator\n",
    "\n",
    "# Data processing with progress updates\n",
    "#print(\"Filtering rejected CVEs...\")\n",
    "nvd = nvd[~nvd.Status.str.contains('Rejected', na=False)]\n",
    "#print(\"Converting dates...\")\n",
    "nvd['Published'] = pd.to_datetime(nvd['Published'])\n",
    "nvd = nvd.sort_values(by=['Published'])\n",
    "nvd = nvd.reset_index(drop=True)\n",
    "nvd['BaseScore'] = pd.to_numeric(nvd['BaseScore'], errors='coerce')\n",
    "nvd['BaseScore'] = nvd['BaseScore'].replace(0, np.nan)\n",
    "\n",
    "# Calculate statistics\n",
    "nvdcount = nvd['Published'].count()\n",
    "nvdunique = nvd['Published'].nunique()\n",
    "pastdata = ((nvd['Published'] > START_DATE) & (nvd['Published']  < str(FORECAST_YEAR)+'-01-01'))\n",
    "thisyear = ((nvd['Published'] > str(FORECAST_YEAR)+'-01-01') & (nvd['Published']  < NEXT_YEAR))\n",
    "nvd_2024 = nvd.loc[thisyear].copy()  # Use .copy() to avoid warnings\n",
    "nvd = nvd.loc[pastdata].copy()\n",
    "\n",
    "startdate = date.fromisoformat(START_DATE)\n",
    "enddate = date.today()\n",
    "numberofdays = enddate - startdate \n",
    "per_day = nvdcount/numberofdays.days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Overview\n",
    "Display summary statistics for the loaded CVE data, including date range, missing values, and severity distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded dataset overview\n",
    "summary = {\n",
    "    'Total CVEs': nvd['CVE'].count(),\n",
    "    'Date Range': f\"{nvd['Published'].min().date()} to {nvd['Published'].max().date()}\",\n",
    "    'Unique Days': nvd['Published'].nunique(),\n",
    "    'Missing BaseScore': nvd['BaseScore'].isnull().sum(),\n",
    "    'Missing Severity': nvd['BaseSeverity'].isnull().sum(),\n",
    "    'Average CVEs Per Day': per_day.round(2),\n",
    "    'Average CVSS Score': nvd['BaseScore'].mean().round(2)\n",
    "}\n",
    "\n",
    "# Use Markdown with line returns for better formatting\n",
    "from IPython.display import display, Markdown\n",
    "output_lines = [f\"**{k}:** {v}\" for k, v in summary.items()]\n",
    "display(Markdown(\"  \\n\".join(output_lines)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Monthly Aggregation\n",
    "Aggregate the CVE data by month for time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T12:10:29.380472Z",
     "iopub.status.busy": "2025-06-29T12:10:29.380065Z",
     "iopub.status.idle": "2025-06-29T12:10:29.419033Z",
     "shell.execute_reply": "2025-06-29T12:10:29.418396Z"
    }
   },
   "outputs": [],
   "source": [
    "nvd['Published'] = pd.to_datetime(nvd['Published'])\n",
    "nvd['Published'] = nvd['Published'].dt.to_period('M').dt.to_timestamp()  # Normalize to start of the month\n",
    "monthly = nvd['Published'].groupby(nvd.Published).agg('count')\n",
    "monthly_cves = pd.DataFrame(monthly)\n",
    "monthly_cves.columns = ['Count']\n",
    "monthly_cves = monthly_cves .reset_index()\n",
    "monthly_cves = monthly_cves.rename(columns={\"Published\" : \"Month\" ,\"Count\": \"CVEs\"})\n",
    "monthly_cves['Month'] = monthly_cves['Month'].astype(str)\n",
    "monthly_cves['Month'] = pd.to_datetime(monthly_cves['Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and validate the monthly_cves data to avoid numerical issues\n",
    "monthly_cves = monthly_cves.replace([np.inf, -np.inf], np.nan)\n",
    "monthly_cves = monthly_cves.dropna(subset=[\"CVEs\"])  # Drop rows where CVEs is NaN\n",
    "monthly_cves = monthly_cves[monthly_cves[\"CVEs\"] > 0]  # Remove zero or negative counts if not meaningful\n",
    "\n",
    "if monthly_cves[\"CVEs\"].isnull().any() or (monthly_cves[\"CVEs\"] == 0).any():\n",
    "    print(\"Warning: monthly_cves still contains NaN or zero values after cleaning.\")\n",
    "\n",
    "monthly_cves = monthly_cves.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Diagnostics\n",
    "Check the length, variance, and distribution of the training data to ensure suitability for forecasting. Visualizations are provided for further insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostics: Check length and variance of training data\n",
    "if len(monthly_cves) < 24:\n",
    "    print(\"Warning: Time series is very short. Consider using a lower dim_x (e.g., 2 or 3) in KalmanForecaster.\")\n",
    "if monthly_cves['CVEs'].var() < 1e-3:\n",
    "    print(\"Warning: Very low variance in time series. KalmanForecaster may be unstable.\")\n",
    "\n",
    "# Visual diagnostics (with error handling for headless environments)\n",
    "try:\n",
    "    plt.figure(figsize=(16,12))\n",
    "    plt.plot(monthly_cves['Month'], monthly_cves['CVEs'], lw=3, color='#1f77b4', marker='o', label='Training Data')\n",
    "    plt.title('Monthly CVE Counts (Training Data)', fontsize=18)\n",
    "    plt.xlabel('Month', fontsize=14)\n",
    "    plt.ylabel('CVEs', fontsize=14)\n",
    "    plt.grid(True, which='both', linestyle='--', alpha=0.6)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Histogram and boxplot (use matching color)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16,5))\n",
    "    monthly_cves['CVEs'].hist(ax=axes[0], bins=12, color='#1f77b4', edgecolor='black')\n",
    "    axes[0].set_title('Histogram of Monthly CVEs', fontsize=14)\n",
    "    axes[0].set_xlabel('CVEs', fontsize=12)\n",
    "    axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "    monthly_cves['CVEs'].plot.box(ax=axes[1], color={'boxes':'#1f77b4','whiskers':'#1f77b4','medians':'#ff7f0e','caps':'#1f77b4'})\n",
    "    axes[1].set_title('Boxplot of Monthly CVEs', fontsize=14)\n",
    "    axes[1].set_ylabel('CVEs', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Note: Plots not displayed (likely running in headless environment): {e}\")\n",
    "    # Still provide text-based diagnostics\n",
    "    print(f\"Training data statistics:\")\n",
    "    print(f\"  Length: {len(monthly_cves)}\")\n",
    "    print(f\"  Mean CVEs/month: {monthly_cves['CVEs'].mean():.1f}\")\n",
    "    print(f\"  Std deviation: {monthly_cves['CVEs'].std():.1f}\")\n",
    "    print(f\"  Min: {monthly_cves['CVEs'].min()}\")\n",
    "    print(f\"  Max: {monthly_cves['CVEs'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Kalman Filter Forecasting\n",
    "Fit the Kalman Forecaster model and generate predictions for the next 12 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T12:10:29.421058Z",
     "iopub.status.busy": "2025-06-29T12:10:29.420546Z",
     "iopub.status.idle": "2025-06-29T12:10:30.125702Z",
     "shell.execute_reply": "2025-06-29T12:10:30.125186Z"
    }
   },
   "outputs": [],
   "source": [
    "train = TimeSeries.from_dataframe(monthly_cves,\"Month\", \"CVEs\")\n",
    "model = KalmanForecaster(dim_x=2)\n",
    "model.fit(train)\n",
    "# Reduced num_samples from 100000 to 1000 for faster CI execution\n",
    "# This still provides good forecast quality while being much faster\n",
    "pred = model.predict(n=12, num_samples=1000)\n",
    "\n",
    "# Plot with error handling for headless environments\n",
    "try:\n",
    "    plt.figure(figsize=(16,12))\n",
    "    train.plot(lw=3)\n",
    "    pred.plot(lw=3, label='forecast')\n",
    "    plt.title('CVE Forecast using Kalman Filter', fontsize=18)\n",
    "    plt.xlabel('Date', fontsize=14)\n",
    "    plt.ylabel('CVEs', fontsize=14)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.grid(True, alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Note: Forecast plot not displayed (likely running in headless environment): {e}\")\n",
    "    print(\"Forecast model trained successfully!\")\n",
    "    print(f\"Prediction range: {pred.start_time()} to {pred.end_time()}\")\n",
    "    print(f\"Number of forecast samples: {len(pred.all_values()[0]) if len(pred.all_values()) > 0 else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Post-Processing Forecast Results\n",
    "Convert the forecast to a DataFrame and summarize monthly predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T12:10:30.127637Z",
     "iopub.status.busy": "2025-06-29T12:10:30.127311Z",
     "iopub.status.idle": "2025-06-29T12:10:30.160631Z",
     "shell.execute_reply": "2025-06-29T12:10:30.160162Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the forecast data from the TimeSeries object\n",
    "darts_df = pred.to_dataframe()\n",
    "\n",
    "# Process the DataFrame as before\n",
    "darts_monthly = darts_df.mean(axis=1).round(0)\n",
    "darts_monthly = darts_monthly.to_frame()\n",
    "darts_monthly = darts_monthly.reset_index()\n",
    "darts_monthly = darts_monthly.rename(columns={0: \"CVEs Predicted\"})\n",
    "darts_monthly['Month'] = darts_monthly['Month'].dt.month_name()\n",
    "darts_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T12:10:30.162629Z",
     "iopub.status.busy": "2025-06-29T12:10:30.162199Z",
     "iopub.status.idle": "2025-06-29T12:10:30.166120Z",
     "shell.execute_reply": "2025-06-29T12:10:30.165658Z"
    }
   },
   "outputs": [],
   "source": [
    "darts_monthly['CVEs Predicted'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Validation Against Actuals\n",
    "Compare the forecasted results to actual CVE counts for 2025. Only the final validation table will be displayed below for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T12:10:30.167714Z",
     "iopub.status.busy": "2025-06-29T12:10:30.167538Z",
     "iopub.status.idle": "2025-06-29T12:10:30.178230Z",
     "shell.execute_reply": "2025-06-29T12:10:30.177751Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare actuals for 2025\n",
    "monthly_2024 = nvd_2024['Published'].groupby(nvd_2024.Published.dt.to_period(\"M\")).agg('count')\n",
    "monthly_cves_2024 = pd.DataFrame(monthly_2024)\n",
    "monthly_cves_2024.columns = ['Count']\n",
    "monthly_cves_2024 = monthly_cves_2024.reset_index()\n",
    "monthly_cves_2024 = monthly_cves_2024.rename(columns={\"Published\" : \"Month\" ,\"Count\": \"CVEs Actual\"})\n",
    "monthly_cves_2024['Month'] = monthly_cves_2024['Month'].astype(str)\n",
    "monthly_cves_2024['Month'] = pd.to_datetime(monthly_cves_2024['Month'])\n",
    "monthly_cves_2024['Month'] = monthly_cves_2024['Month'].dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T12:10:30.179970Z",
     "iopub.status.busy": "2025-06-29T12:10:30.179707Z",
     "iopub.status.idle": "2025-06-29T12:10:30.192200Z",
     "shell.execute_reply": "2025-06-29T12:10:30.191699Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge actuals and predictions, sort, and calculate summary statistics\n",
    "validation_df = pd.merge(\n",
    "    monthly_cves_2024,\n",
    "    darts_monthly,\n",
    "    how=\"outer\",\n",
    "    on='Month',\n",
    ")\n",
    "\n",
    "month_categories = ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "                    'July', 'August', 'September', 'October', 'November', 'December', 'Total']\n",
    "\n",
    "validation_df['Month'] = pd.Categorical(validation_df['Month'], categories = month_categories, ordered = True)\n",
    "validation_df = validation_df.sort_values(by='Month')\n",
    "\n",
    "# Calculate difference and fill missing values\n",
    "validation_df['Difference'] = validation_df['CVEs Actual'] - validation_df['CVEs Predicted']\n",
    "validation_df['CVEs Actual'] = validation_df['CVEs Actual'].fillna(0)\n",
    "validation_df['Difference'] = validation_df['Difference'].fillna(0)\n",
    "\n",
    "# Add total row\n",
    "numeric_df = validation_df.select_dtypes(include=np.number)\n",
    "total_row = numeric_df.sum(numeric_only=True)\n",
    "validation_df = pd.concat([validation_df, pd.DataFrame(total_row.rename('Total')).T], ignore_index=True)\n",
    "validation_df['CVEs Actual'] = validation_df['CVEs Actual'].fillna(0)\n",
    "validation_df['Difference'] = validation_df['Difference'].fillna(0)\n",
    "\n",
    "# Add percentage column\n",
    "\n",
    "def percentage_change(col1, col2):\n",
    "    return ((col2 / col1) * 100).round(0)\n",
    "\n",
    "validation_df['Precentage'] = percentage_change(validation_df['CVEs Predicted'], validation_df['CVEs Actual'])   \n",
    "validation_df['Precentage'] = validation_df['Precentage'].fillna(0)\n",
    "validation_df.at[12,'Month']='Total'\n",
    "\n",
    "# Show only the final validation table\n",
    "validation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "This notebook demonstrates the use of the Kalman Filter for time series forecasting of CVE counts, with validation against actual 2025 data. Adjustments and further analysis can be performed as new data becomes available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
